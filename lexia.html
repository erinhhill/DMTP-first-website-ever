<!DOCTYPE HTML>
<html>
<head>
<link rel="stylesheet" type="text/css" href="my_styles.css">
<title>Lexias</title>
</head>

<body>
<section>
<div id="mySidenav" class="sidenav">
  <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
  <a href="home.html">Home</a>
  <a href="photonewpage.html">See</a>
  <a href="video.html">Feel</a>
  <a href="audio.html">Listen</a>
</div>


<span style="font-size:30px;cursor:pointer" onclick="openNav()">&#9776;</span>

<script>
function openNav() {
    document.getElementById("mySidenav").style.width = "250px";
}

function closeNav() {
    document.getElementById("mySidenav").style.width = "0";
}
</script>
</section>

<div style="text-align:center">
<br>
Elegance, in the modern sense, has become less of a list of features and more of an absolute requirement for any digital media fit to be in the hands of the consumers. It is no longer four criteria that Donald Knuth proposed to define elegance as "leanness of the code; the clarity with which the problem is defined; spareness of use of resources such as the time and process cycles; and, implementation in the most suitable language on the most suitable system for its execution" (Fuller 87). To further discuss this shift in attitude towards elegance, it is helpful to consider Apple technology as an example.
	Apple has made its mission as a company to provide what they see as elegant, simple, top-quality software with sleek designs easily available and navigable to their customers. In a sense, they have spearheaded the revolution from elegance as a personal goal to elegance as a product marketed to consumers. Elegance now is a type of aesthetic; sleek, chrome, smooth, and minimal. This translates into their software as well. It is self-monitoring, requiring minimal user intervention in cases where something abnormal occurs, and has simplified its own path as a trajectory "through possible conditions of failure" (Fuller 90). This has arguably changed the definition of elegance through trickle down economics. As more and more tech companies adopted this philosophy of necessary elegance with minimal physical interaction with the user, elegance has become a requirement for "good" consumer software.
	Interestingly a recent rise in indie developers has lead to a counter-argument about whether this is what makes software "elegant". A small but significant portion of users find Apple, Microsoft interfaces as insufficient to meeting their needs and take it upon themselves to create what they need instead. While it may not be elegant in the traditional Apple aesthetic sense, perhaps it is elegant in a different way. Fewer computational errors, faster speeds, and true customization may instead be what classifies as elegance. In this sense, we may consider that elegance is no longer a set of defined criteria but rather depends on personal needs, knowledge, and preference.
    <br>
    <br>
    <br>
Secondary Response on <a href="http://www.composingdigitalmedia.org/f16_dmtpW/webs/lse/lexicon1.html">Seth's Lexia on Ethnocomputing</a>
<br>
"Social media sites have allowed cultural and personal identities to flourish, suggesting an intense relationship between how users use technology and how the affordances of technology appear, morph, and present themselves to different societies and cultures in different spaces marked by hegemonic ideas of location and time" - Seth
<br>
<br>
Exploring this idea further, we see underlying trends in various cultures in relation to personal identities, but what if, today, the cultivation of these perceived personal identities has outweighed the importance of actually developing them? I'd like to use Instagram as an example. The visual media-based app has become so popular and integral to the heartbeat of millennial social media that kids will often agonize over the aesthetics of their feed, or wait months just to take and post the perfect picture. In shifting the focus from personal identity to perceived identity, social media has become a deterrent in showing everything you want to. Some may feel that to cultivate the "perfect" online identity they must censor themselves fully, or hold back in some way. 

Alternatively, however, the recent rise in "finstagrams" may counter my argument very nicely. As a way to detach themselves from the carefully planned and created aesthetic of their main profile, Instagram users have been creating secondary accounts for only close friends known as "finstas" where they may actually be more able to develop a personal identity due to the personal nature of their audience. Users spend less time censoring themselves and their content by posting more casually than worrying about how they present themselves to a wider audience and maintaining a certain aesthetic. Content generated on finstas are much more representative of a true personal identity being shown on social media, and the increasing trend in these accounts suggests we may be ready to make the leap from cultivating our social media to simply using it as a window into our actual lives for friends and those we care about.
<br>
<br>
<br>
Tertiary Response to <a href="http://composingdigitalmedia.org/f16_dmtpW/webs/wab/lexicon.html">Abby's Lexia on Intelligence</a>
<br>
<br>
In Seth's response to Abby's lexia on intelligence, I agree with the idea that needing to "become" human is very problematic, so it's interesting that when thinking about AI in pop-culture, specifically film, most problems in the story arise when scientists attempt to create human-like intelligence in robots. Giving them complex thought and emotions always seems to lead to human enslavement, apocalyptic scenarios, and the like. It is curious then, our obsession with making AI as similar to humans as possible. As Abby points out, these autonomous machines begin to rely less and less on their creators, an idea that has clearly captivated Hollywood and most consumers of pop-culture, but what of actual scientists in the real world? When looking at self-driving cars for example, would intelligence of that AI be classified by how "human" it is, or how fast and accurate it is? Intelligence then, seems to be much more of a subjective term these days. As Seth points out in his response, these forms of AI can and must be the actants for the purpose of which they were created, to assist us in whatever we deem necessary. There seems to be a large disparity between what the general public deems intelligence and what engineers and scientists consider it to mean in the context of technology.
<br>
<br>
Secondary Response to <a href="http://www.composingdigitalmedia.org/f16_dmtpW/webs/kxi/pixel.html">Shereen's Lexia on Pixels</a>
<br>
<br>
Shereen raises an interesting point in her argument that the "pixel" aesthetic has been becoming less and less popular among consumers and producers of certain types of media, but I would like to examine the rise in popularity of pixel art in other types of media, specifically digital art and independently developed video games. Indie developers in the gaming world have caused a shift in graphics development from the high definition ones seen in studio-developed games to the nostaligic pixel graphics of games such as "Super Mario Bros." as Shereen mentioned in her lexia. This trend in pixel art suggests that the newest generation of content creators, the ones that grew up on pixelated digital media, are fond of using pixel art that invokes the same feelings of childlike wonder and nostalgia that this generation felt as kids playing these games. A good example of this would be popular indie games such as "Super Meat Boy" "Fez" or "Shovel Knight." All three games are built on incredibly advanved systems with modern mechanics but with 2D art remniscient of those first Mario, Legend of Zelda, and Atari games so popular in the 80's and 90's. That is why I think that there is a trend towards pixelation in certain types of media as opposed to away from it.

</div>
</body>
</html>